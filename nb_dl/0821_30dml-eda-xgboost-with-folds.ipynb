{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:41.761053Z",
     "iopub.status.busy": "2021-08-17T11:47:41.760604Z",
     "iopub.status.idle": "2021-08-17T11:47:43.207704Z",
     "shell.execute_reply": "2021-08-17T11:47:43.206968Z",
     "shell.execute_reply.started": "2021-08-17T11:47:41.760946Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBRegressor\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:43.209588Z",
     "iopub.status.busy": "2021-08-17T11:47:43.209112Z",
     "iopub.status.idle": "2021-08-17T11:47:49.198491Z",
     "shell.execute_reply": "2021-08-17T11:47:49.197702Z",
     "shell.execute_reply.started": "2021-08-17T11:47:43.209554Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/30-days-of-ml/train.csv\", low_memory=False)\n",
    "test = pd.read_csv(\"/kaggle/input/30-days-of-ml/test.csv\", low_memory=False)\n",
    "train.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:49.200618Z",
     "iopub.status.busy": "2021-08-17T11:47:49.200302Z",
     "iopub.status.idle": "2021-08-17T11:47:49.790048Z",
     "shell.execute_reply": "2021-08-17T11:47:49.78895Z",
     "shell.execute_reply.started": "2021-08-17T11:47:49.200584Z"
    }
   },
   "outputs": [],
   "source": [
    "test.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:49.791903Z",
     "iopub.status.busy": "2021-08-17T11:47:49.791583Z",
     "iopub.status.idle": "2021-08-17T11:47:49.834154Z",
     "shell.execute_reply": "2021-08-17T11:47:49.833086Z",
     "shell.execute_reply.started": "2021-08-17T11:47:49.791872Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:49.835832Z",
     "iopub.status.busy": "2021-08-17T11:47:49.835553Z",
     "iopub.status.idle": "2021-08-17T11:47:49.843569Z",
     "shell.execute_reply": "2021-08-17T11:47:49.842236Z",
     "shell.execute_reply.started": "2021-08-17T11:47:49.835804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Colors to be used for plots\n",
    "colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n",
    "          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n",
    "          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n",
    "          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:49.845064Z",
     "iopub.status.busy": "2021-08-17T11:47:49.844736Z",
     "iopub.status.idle": "2021-08-17T11:47:49.991137Z",
     "shell.execute_reply": "2021-08-17T11:47:49.990291Z",
     "shell.execute_reply.started": "2021-08-17T11:47:49.845025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing the datasets length\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "pie = ax.pie([len(train), len(test)],\n",
    "             labels=[\"Train dataset\", \"Test dataset\"],\n",
    "             colors=[\"salmon\", \"teal\"],\n",
    "             textprops={\"fontsize\": 15},\n",
    "             autopct='%1.1f%%')\n",
    "ax.axis(\"equal\")\n",
    "ax.set_title(\"Dataset length comparison\", fontsize=18)\n",
    "fig.set_facecolor('white')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:49.992592Z",
     "iopub.status.busy": "2021-08-17T11:47:49.992185Z",
     "iopub.status.idle": "2021-08-17T11:47:50.29503Z",
     "shell.execute_reply": "2021-08-17T11:47:50.293892Z",
     "shell.execute_reply.started": "2021-08-17T11:47:49.992561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Statistical description of the train dataset\n",
    "train.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:50.297956Z",
     "iopub.status.busy": "2021-08-17T11:47:50.297585Z",
     "iopub.status.idle": "2021-08-17T11:47:50.811641Z",
     "shell.execute_reply": "2021-08-17T11:47:50.810587Z",
     "shell.execute_reply.started": "2021-08-17T11:47:50.29792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking if there are missing values in the datasets\n",
    "train.isna().sum().sum(), test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing value in the both datasets.\n",
    "\n",
    "Let's check target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:50.814238Z",
     "iopub.status.busy": "2021-08-17T11:47:50.813917Z",
     "iopub.status.idle": "2021-08-17T11:47:51.198675Z",
     "shell.execute_reply": "2021-08-17T11:47:51.197618Z",
     "shell.execute_reply.started": "2021-08-17T11:47:50.814208Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "bars = ax.hist(train[\"target\"],\n",
    "               bins=100,\n",
    "               color=\"palevioletred\",\n",
    "               edgecolor=\"black\")\n",
    "ax.set_title(\"Target distribution\", fontsize=20, pad=15)\n",
    "ax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\n",
    "ax.set_xlabel(\"Target value\", fontsize=14, labelpad=10)\n",
    "ax.margins(0.025, 0.12)\n",
    "ax.grid(axis=\"y\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:51.200367Z",
     "iopub.status.busy": "2021-08-17T11:47:51.199953Z",
     "iopub.status.idle": "2021-08-17T11:47:51.225597Z",
     "shell.execute_reply": "2021-08-17T11:47:51.224402Z",
     "shell.execute_reply.started": "2021-08-17T11:47:51.200259Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{(train['target'] < 5).sum() / len(train) * 100:.3f}% of the target values are less than 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains categorical and numerical values. Let's see values distribution for these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:51.227673Z",
     "iopub.status.busy": "2021-08-17T11:47:51.227238Z",
     "iopub.status.idle": "2021-08-17T11:47:51.233228Z",
     "shell.execute_reply": "2021-08-17T11:47:51.232061Z",
     "shell.execute_reply.started": "2021-08-17T11:47:51.227618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lists of categorical and numerical feature columns\n",
    "cat_features = [\"cat\" + str(i) for i in range(10)]\n",
    "num_features = [\"cont\" + str(i) for i in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:51.23532Z",
     "iopub.status.busy": "2021-08-17T11:47:51.23492Z",
     "iopub.status.idle": "2021-08-17T11:47:56.555471Z",
     "shell.execute_reply": "2021-08-17T11:47:56.554696Z",
     "shell.execute_reply.started": "2021-08-17T11:47:51.235275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combined dataframe containing numerical features only\n",
    "df = pd.concat([train[num_features], test[num_features]], axis=0)\n",
    "columns = df.columns.values\n",
    "\n",
    "# Calculating required amount of rows to display all feature plots\n",
    "cols = 3\n",
    "rows = len(columns) // cols + 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,20), sharex=False)\n",
    "\n",
    "# Adding some distance between plots\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "\n",
    "# Plots counter\n",
    "i=0\n",
    "for r in np.arange(0, rows, 1):\n",
    "    for c in np.arange(0, cols, 1):\n",
    "        if i >= len(columns): # If there is no more data columns to make plots from\n",
    "            axs[r, c].set_visible(False) # Hiding axes so there will be clean background\n",
    "        else:\n",
    "            # Train data histogram\n",
    "            hist1 = axs[r, c].hist(train[columns[i]].values,\n",
    "                                   range=(df[columns[i]].min(),\n",
    "                                          df[columns[i]].max()),\n",
    "                                   bins=40,\n",
    "                                   color=\"deepskyblue\",\n",
    "                                   edgecolor=\"black\",\n",
    "                                   alpha=0.7,\n",
    "                                   label=\"Train Dataset\")\n",
    "            # Test data histogram\n",
    "            hist2 = axs[r, c].hist(test[columns[i]].values,\n",
    "                                   range=(df[columns[i]].min(),\n",
    "                                          df[columns[i]].max()),\n",
    "                                   bins=40,\n",
    "                                   color=\"palevioletred\",\n",
    "                                   edgecolor=\"black\",\n",
    "                                   alpha=0.7,\n",
    "                                   label=\"Test Dataset\")\n",
    "            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n",
    "            axs[r, c].tick_params(axis=\"y\", labelsize=13)\n",
    "            axs[r, c].tick_params(axis=\"x\", labelsize=13)\n",
    "            axs[r, c].grid(axis=\"y\")\n",
    "            axs[r, c].legend(fontsize=13)\n",
    "                                  \n",
    "        i+=1\n",
    "# plt.suptitle(\"Numerical feature values distribution in both datasets\", y=0.99)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:47:56.556978Z",
     "iopub.status.busy": "2021-08-17T11:47:56.556564Z",
     "iopub.status.idle": "2021-08-17T11:48:05.455705Z",
     "shell.execute_reply": "2021-08-17T11:48:05.454683Z",
     "shell.execute_reply.started": "2021-08-17T11:47:56.556935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combined dataframe containing categorical features only\n",
    "df = pd.concat([train[cat_features], test[cat_features]], axis=0)\n",
    "columns = df.columns.values\n",
    "\n",
    "# Calculating required amount of rows to display all feature plots\n",
    "cols = 3\n",
    "rows = len(columns) // cols + 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,20), sharex=False)\n",
    "\n",
    "# Adding some distance between plots\n",
    "plt.subplots_adjust(hspace = 0.2, wspace=0.25)\n",
    "\n",
    "# Plots counter\n",
    "i=0\n",
    "for r in np.arange(0, rows, 1):\n",
    "    for c in np.arange(0, cols, 1):\n",
    "        if i >= len(cat_features): # If there is no more data columns to make plots from\n",
    "            axs[r, c].set_visible(False) # Hiding axes so there will be clean background\n",
    "        else:\n",
    "\n",
    "            values = df[cat_features[i]].value_counts().sort_index(ascending=False).index\n",
    "            bars_pos = np.arange(0, len(values))\n",
    "            if len(values)<4:\n",
    "                height=0.1\n",
    "            else:\n",
    "                height=0.3\n",
    "\n",
    "            bars1 = axs[r, c].barh(bars_pos+height/2,\n",
    "                                   [train[train[cat_features[i]]==x][cat_features[i]].count() for x in values],\n",
    "                                   height=height,\n",
    "                                   color=\"teal\",\n",
    "                                   edgecolor=\"black\",\n",
    "                                   label=\"Train Dataset\")\n",
    "            bars2 = axs[r, c].barh(bars_pos-height/2,\n",
    "                                   [test[test[cat_features[i]]==x][cat_features[i]].count() for x in values],\n",
    "                                   height=height,\n",
    "                                   color=\"salmon\",\n",
    "                                   edgecolor=\"black\",\n",
    "                                   label=\"Test Dataset\")\n",
    "            y_labels = [str(x) for x in values]\n",
    "\n",
    "            axs[r, c].set_title(cat_features[i], fontsize=14, pad=1)\n",
    "            axs[r, c].set_xlim(0, len(train[\"id\"])+50)\n",
    "            axs[r, c].set_yticks(bars_pos)\n",
    "            axs[r, c].set_yticklabels(y_labels)\n",
    "            axs[r, c].tick_params(axis=\"y\", labelsize=10)\n",
    "            axs[r, c].tick_params(axis=\"x\", labelsize=10)\n",
    "            axs[r, c].grid(axis=\"x\")\n",
    "            axs[r, c].legend(fontsize=12)\n",
    "            axs[r, c].margins(0.1, 0.02)\n",
    "                                  \n",
    "        i+=1\n",
    "\n",
    "#plt.suptitle(\"Categorical feature values distribution in both datasets\", y=0.99)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the datasets have different amount of categories in categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:05.457622Z",
     "iopub.status.busy": "2021-08-17T11:48:05.457198Z",
     "iopub.status.idle": "2021-08-17T11:48:06.791991Z",
     "shell.execute_reply": "2021-08-17T11:48:06.790959Z",
     "shell.execute_reply.started": "2021-08-17T11:48:05.457578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bars position should be numerical because there will be arithmetical operations with them\n",
    "bars_pos = np.arange(len(cat_features))\n",
    "\n",
    "width=0.3\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "# Making two bar objects. One is on the left from bar position and the other one is on the right\n",
    "bars1 = ax.bar(bars_pos-width/2,\n",
    "               train[cat_features].nunique().values,\n",
    "               width=width,\n",
    "               color=\"darkorange\", edgecolor=\"black\")\n",
    "bars2 = ax.bar(bars_pos+width/2,\n",
    "               train[cat_features].nunique().values,\n",
    "               width=width,\n",
    "               color=\"steelblue\", edgecolor=\"black\")\n",
    "ax.set_title(\"Amount of values in categorical features\", fontsize=20, pad=15)\n",
    "ax.set_xlabel(\"Categorical feature\", fontsize=15, labelpad=15)\n",
    "ax.set_ylabel(\"Amount of values\", fontsize=15, labelpad=15)\n",
    "ax.set_xticks(bars_pos)\n",
    "ax.set_xticklabels(cat_features, fontsize=12)\n",
    "ax.tick_params(axis=\"y\", labelsize=12)\n",
    "ax.grid(axis=\"y\")\n",
    "plt.margins(0.01, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:06.794016Z",
     "iopub.status.busy": "2021-08-17T11:48:06.79359Z",
     "iopub.status.idle": "2021-08-17T11:48:07.917108Z",
     "shell.execute_reply": "2021-08-17T11:48:07.916055Z",
     "shell.execute_reply.started": "2021-08-17T11:48:06.793978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking if test data doesn't contain categories that are not present in the train dataset\n",
    "for col in cat_features:\n",
    "    print(set(train[col].value_counts().index) == set(test[col].value_counts().index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the datasets are pretty well balanced. Let's look at feature correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:07.919296Z",
     "iopub.status.busy": "2021-08-17T11:48:07.918877Z",
     "iopub.status.idle": "2021-08-17T11:48:11.866463Z",
     "shell.execute_reply": "2021-08-17T11:48:11.865306Z",
     "shell.execute_reply.started": "2021-08-17T11:48:07.919249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot dataframe\n",
    "df = train.drop(\"id\", axis=1)\n",
    "\n",
    "# Encoding categorical features with OrdinalEncoder\n",
    "for col in cat_features:\n",
    "    encoder = OrdinalEncoder()\n",
    "    df[col] = encoder.fit_transform(np.array(df[col]).reshape(-1, 1))\n",
    "\n",
    "# Calculatin correlation values\n",
    "df = df.corr().round(2)\n",
    "\n",
    "# Mask to hide upper-right part of plot as it is a duplicate\n",
    "mask = np.zeros_like(df)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Making a plot\n",
    "plt.figure(figsize=(14,14))\n",
    "ax = sns.heatmap(df, annot=True, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"normal\", \"fontsize\":9})\n",
    "ax.set_title(\"Feature correlation heatmap\", fontsize=17)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\", weight=\"normal\")\n",
    "plt.setp(ax.get_yticklabels(), weight=\"normal\",\n",
    "         rotation_mode=\"anchor\", rotation=0, ha=\"right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, target column is very weakly correlated with all features.\n",
    "\n",
    "Let's visualize each feature vs target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:11.868714Z",
     "iopub.status.busy": "2021-08-17T11:48:11.868284Z",
     "iopub.status.idle": "2021-08-17T11:48:28.071896Z",
     "shell.execute_reply": "2021-08-17T11:48:28.070912Z",
     "shell.execute_reply.started": "2021-08-17T11:48:11.868668Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = train.drop([\"id\", \"target\"], axis=1).columns.values\n",
    "\n",
    "# Calculating required amount of rows to display all feature plots\n",
    "cols = 4\n",
    "rows = len(columns) // cols + 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,20), sharex=False)\n",
    "\n",
    "# Adding some distance between plots\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "\n",
    "i=0\n",
    "for r in np.arange(0, rows, 1):\n",
    "    for c in np.arange(0, cols, 1):\n",
    "        if i >= len(columns):\n",
    "            axs[r, c].set_visible(False)\n",
    "        else:\n",
    "            scatter = axs[r, c].scatter(train[columns[i]].values,\n",
    "                                        train[\"target\"],\n",
    "                                        color=random.choice(colors))\n",
    "            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n",
    "            axs[r, c].tick_params(axis=\"y\", labelsize=11)\n",
    "            axs[r, c].tick_params(axis=\"x\", labelsize=11)\n",
    "                                  \n",
    "        i+=1\n",
    "# plt.suptitle(\"Features vs target\", y=0.99)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:28.073447Z",
     "iopub.status.busy": "2021-08-17T11:48:28.073154Z",
     "iopub.status.idle": "2021-08-17T11:48:30.243826Z",
     "shell.execute_reply": "2021-08-17T11:48:30.242803Z",
     "shell.execute_reply.started": "2021-08-17T11:48:28.073419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoding categorical features with OrdinalEncoder\n",
    "for col in cat_features:\n",
    "    encoder = OrdinalEncoder()\n",
    "    train[col] = encoder.fit_transform(np.array(train[col]).reshape(-1, 1))\n",
    "    test[col] = encoder.transform(np.array(test[col]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:30.245464Z",
     "iopub.status.busy": "2021-08-17T11:48:30.245148Z",
     "iopub.status.idle": "2021-08-17T11:48:30.367228Z",
     "shell.execute_reply": "2021-08-17T11:48:30.366255Z",
     "shell.execute_reply.started": "2021-08-17T11:48:30.245432Z"
    }
   },
   "outputs": [],
   "source": [
    "train[cat_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:30.368739Z",
     "iopub.status.busy": "2021-08-17T11:48:30.368439Z",
     "iopub.status.idle": "2021-08-17T11:48:30.435117Z",
     "shell.execute_reply": "2021-08-17T11:48:30.434147Z",
     "shell.execute_reply.started": "2021-08-17T11:48:30.368709Z"
    }
   },
   "outputs": [],
   "source": [
    "test[cat_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T11:48:30.436741Z",
     "iopub.status.busy": "2021-08-17T11:48:30.436454Z",
     "iopub.status.idle": "2021-08-17T11:48:30.513268Z",
     "shell.execute_reply": "2021-08-17T11:48:30.512072Z",
     "shell.execute_reply.started": "2021-08-17T11:48:30.436713Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.drop([\"id\", \"target\"], axis=1)\n",
    "X_test = test.drop([\"id\"], axis=1)\n",
    "y = train[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T12:37:25.583759Z",
     "iopub.status.busy": "2021-08-17T12:37:25.583138Z",
     "iopub.status.idle": "2021-08-17T12:37:25.590165Z",
     "shell.execute_reply": "2021-08-17T12:37:25.588897Z",
     "shell.execute_reply.started": "2021-08-17T12:37:25.583704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "xgb_params = {'n_estimators': 10000,\n",
    "              'learning_rate': 0.35,\n",
    "              'subsample': 0.926,\n",
    "              'colsample_bytree': 0.84,\n",
    "              'max_depth': 2,\n",
    "              'booster': 'gbtree', \n",
    "              'reg_lambda': 35.1,\n",
    "              'reg_alpha': 34.9,\n",
    "              'random_state': 42,\n",
    "              'n_jobs': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T12:37:25.961579Z",
     "iopub.status.busy": "2021-08-17T12:37:25.961198Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Setting up fold parameters\n",
    "splits = 10\n",
    "skf = KFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Creating an array of zeros for storing \"out of fold\" predictions\n",
    "oof_preds = np.zeros((X.shape[0],))\n",
    "preds = 0\n",
    "model_fi = 0\n",
    "total_mean_rmse = 0\n",
    "\n",
    "# Generating folds and making training and prediction for each of 10 folds\n",
    "for num, (train_idx, valid_idx) in enumerate(skf.split(X)):\n",
    "    X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "    \n",
    "    model = XGBRegressor(**xgb_params)\n",
    "    model.fit(X_train, y_train,\n",
    "              verbose=False,\n",
    "              # These three parameters will stop training before a model starts overfitting \n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              eval_metric=\"rmse\",\n",
    "              early_stopping_rounds=100,\n",
    "              )\n",
    "    \n",
    "    # Getting mean test data predictions (i.e. devided by number of splits)\n",
    "    preds += model.predict(X_test) / splits\n",
    "    \n",
    "    # Getting mean feature importances (i.e. devided by number of splits)\n",
    "    model_fi += model.feature_importances_ / splits\n",
    "    \n",
    "    # Getting validation data predictions. Each fold model makes predictions on an unseen data.\n",
    "    # So in the end it will be completely filled with unseen data predictions.\n",
    "    # It will be used to evaluate hyperparameters performance only.\n",
    "    oof_preds[valid_idx] = model.predict(X_valid)\n",
    "    \n",
    "    # Getting score for a fold model\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_idx]))\n",
    "    print(f\"Fold {num} RMSE: {fold_rmse}\")\n",
    "\n",
    "    # Getting mean score of all fold models (i.e. devided by number of splits)\n",
    "    total_mean_rmse += fold_rmse / splits\n",
    "    \n",
    "print(f\"\\nOverall RMSE: {total_mean_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T12:36:24.33384Z",
     "iopub.status.busy": "2021-08-17T12:36:24.333248Z",
     "iopub.status.idle": "2021-08-17T12:36:24.344168Z",
     "shell.execute_reply": "2021-08-17T12:36:24.343315Z",
     "shell.execute_reply.started": "2021-08-17T12:36:24.333788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe to be used for plotting\n",
    "df = pd.DataFrame()\n",
    "df[\"Feature\"] = X.columns\n",
    "# Extracting feature importances from the trained model\n",
    "df[\"Importance\"] = model_fi / model_fi.sum()\n",
    "# Sorting the dataframe by feature importance\n",
    "df.sort_values(\"Importance\", axis=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T12:36:25.54491Z",
     "iopub.status.busy": "2021-08-17T12:36:25.544361Z",
     "iopub.status.idle": "2021-08-17T12:36:26.233586Z",
     "shell.execute_reply": "2021-08-17T12:36:26.2327Z",
     "shell.execute_reply.started": "2021-08-17T12:36:25.544847Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "bars = ax.barh(df[\"Feature\"], df[\"Importance\"], height=0.4,\n",
    "               color=\"mediumorchid\", edgecolor=\"black\")\n",
    "ax.set_title(\"Feature importances\", fontsize=30, pad=15)\n",
    "ax.set_ylabel(\"Feature name\", fontsize=20, labelpad=15)\n",
    "ax.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\n",
    "ax.set_yticks(df[\"Feature\"])\n",
    "ax.set_yticklabels(df[\"Feature\"], fontsize=15)\n",
    "ax.tick_params(axis=\"x\", labelsize=15)\n",
    "ax.grid(axis=\"x\")\n",
    "# Adding labels on top\n",
    "ax2 = ax.secondary_xaxis('top')\n",
    "ax2.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\n",
    "ax2.tick_params(axis=\"x\", labelsize=15)\n",
    "\n",
    "# Inverting y axis direction so the values are decreasing\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictions submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T12:36:32.794877Z",
     "iopub.status.busy": "2021-08-17T12:36:32.794467Z",
     "iopub.status.idle": "2021-08-17T12:36:33.417764Z",
     "shell.execute_reply": "2021-08-17T12:36:33.416975Z",
     "shell.execute_reply.started": "2021-08-17T12:36:32.794827Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions[\"id\"] = test[\"id\"]\n",
    "predictions[\"target\"] = preds\n",
    "\n",
    "predictions.to_csv('submission.csv', index=False, header=predictions.columns)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
